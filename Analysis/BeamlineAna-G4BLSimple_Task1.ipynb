{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d654f053-feea-4127-94e5-c359f12b37f0",
   "metadata": {},
   "source": [
    "# Beamline Analyzer\n",
    "### Uses G4Beamline \"simple\" files as input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65442860-0823-4297-add8-c5f15dd59b42",
   "metadata": {},
   "source": [
    "## Simulation Configuration Input\n",
    "\n",
    "*config09_2* is the final update stage of *config09*.\n",
    "\n",
    "**Detector common in both *_1* and *_2* versions:**\n",
    "- JGGDet1\n",
    "- JGGDet2\n",
    "- JGGDet3\n",
    "- Det7\n",
    "- DetT2\n",
    "\n",
    "**Changes applied:**\n",
    "- DetT0 was added: more upstream placement of a virtual detector, to both compare the beam flux with StartLine and to trigger events with four detectors (Det7, JGGDet1 + DetT0, DetT2).\n",
    "- DetT1 was placed more US; it probably won't be used.\n",
    "- StartLine was added in the making of the TTrees to compare the beam flux with DetT0 as said before.\n",
    "\n",
    "**Note:** *DetT0 is placed just after the two LArIAT magnets, B1 and B2. DetT1, instead, is placed near LArIAT WCs.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b21134-efe5-4f67-8691-f0055dc79414",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0522e192-bac6-4002-b663-35d215e9a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import uproot\n",
    "import math\n",
    "from glob import glob\n",
    "import awkward as ak\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import get_cmap\n",
    "%matplotlib inline\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "_colors = prop_cycle.by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58c1bfb-949b-436c-a51e-81131119f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_dir = 'plots/lariat_off_JGG_on/T2/'\n",
    "\n",
    "colors = [\n",
    "    '#2c5d77',  # Deep Sky Blue\n",
    "    '#4a7a9b',  # Medium Blue Gray\n",
    "    '#6a9bb9',  # Light Steel Blue\n",
    "    '#94c7d6',  # Soft Blue\n",
    "    '#cbe4eb',  # Slightly Darker Pale Blue \n",
    "    '#c1d0da',  # Light Blue Gray\n",
    "    '#d1dce3',  # Darker Light Gray \n",
    "    '#e1e8ed'   # Very Light Gray\n",
    "]\n",
    "\n",
    "\n",
    "#colors = plt.cm.Set1(np.linspace(0, 1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350eb88a-be59-46a7-b825-96865bf1e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config05_2, better JGG with field\n",
    "# f = '/pnfs/lariat/persistent/users/mdeltutt/BeamLineSimOutputs/pos60Amps/config05_2/merged_sim_arcs_beamline_simple_9858of30k.root'\n",
    "# n_pions = 9858 * 30000\n",
    "# config = 'config05_2'\n",
    "\n",
    "# config07_1, BFIELD=0\n",
    "# f = '/pnfs/lariat/persistent/users/mdeltutt/BeamLineSimOutputs/pos60Amps/config07_1/merged_sim_arcs_beamline_simple_9511of30k_config07_1.root'\n",
    "# f = '/Users/mdeltutt/OneDrive - Fermi National Accelerator Laboratory/Work/ArCS/beamline/files/merged_sim_arcs_beamline_simple_9511of30k_config07_1.root'\n",
    "# n_pions = 9511 * 30000\n",
    "# config = 'config07_1'\n",
    "\n",
    "# config08_1, BFIELD=0, cryo and LAr\n",
    "f = '/pnfs/lariat/persistent/users/gcicogna/BeamLineSimOutputs/pos60Amps/config09_2/merged_sim_arcs_beamline_simple_5706of30k_config09_2.root'\n",
    "\n",
    "n_pions = 5706 * 30000\n",
    "config = 'config09_2'\n",
    "\n",
    "det_beam = ['StartLine', 'DetT0']\n",
    "det_list = ['DetT0', 'Det7', 'JGGDet1']\n",
    "#det_list = ['DetT2', 'Det7', 'JGGDet1']\n",
    "det_four = ['DetT0', 'DetT2', 'Det7', 'JGGDet1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1775cbe8-37f7-479d-92d8-5a01dca20b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectors: ['VirtualDetector;1', 'VirtualDetector/StartLine;1', 'VirtualDetector/Det7;1', 'VirtualDetector/DetT0;1', 'VirtualDetector/DetT1;1', 'VirtualDetector/DetT2;1', 'VirtualDetector/JGGDet1;1', 'VirtualDetector/JGGDet2;1', 'VirtualDetector/JGGDet3;1']\n",
      "Number of pions: 171180000\n",
      "Number of spills: 684.72\n",
      "Number of hours: 11.412\n",
      "Number of months: 0.01585\n"
     ]
    }
   ],
   "source": [
    "file = uproot.open(f)\n",
    "print('Detectors:', file.keys())\n",
    "\n",
    "n_spills = n_pions / 2.5e5\n",
    "n_hours = n_spills / 60\n",
    "n_months = n_spills / 60 / 24 / 30\n",
    "\n",
    "print('Number of pions:', n_pions)\n",
    "print('Number of spills:', n_spills)\n",
    "print('Number of hours:', n_hours)\n",
    "print('Number of months:', n_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664372c0-f740-4990-95bf-42c32b9c66ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTree variables: ['x', 'y', 'z', 'Px', 'Py', 'Pz', 't', 'PDGid', 'EventID', 'TrackID', 'ParentID', 'Weight']\n",
      "Number of entries in StartLine: 972610446\n",
      "Number of entries in DetT0: 399460266\n",
      "Number of entries in DetT1: 115252215\n",
      "Number of entries in DetT2: 16263867\n",
      "Number of entries in Det7: 15429929\n",
      "Number of entries in JGGDet1: 33506585\n"
     ]
    }
   ],
   "source": [
    "print('TTree variables:', file[f'VirtualDetector/JGGDet1'].keys())\n",
    "print('Number of entries in StartLine:', file[f'VirtualDetector/StartLine'].num_entries)\n",
    "#print('Number of entries in Det4:', file[f'VirtualDetector/Det4'].num_entries)\n",
    "print('Number of entries in DetT0:', file[f'VirtualDetector/DetT0'].num_entries)\n",
    "print('Number of entries in DetT1:', file[f'VirtualDetector/DetT1'].num_entries)\n",
    "print('Number of entries in DetT2:', file[f'VirtualDetector/DetT2'].num_entries)\n",
    "print('Number of entries in Det7:', file[f'VirtualDetector/Det7'].num_entries)\n",
    "print('Number of entries in JGGDet1:', file[f'VirtualDetector/JGGDet1'].num_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb83352-fb50-44ce-83fa-88c157e1685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vars_to_df(df):\n",
    "    '''\n",
    "    Adds total momentum, as well as theta and phi, to the dataframe\n",
    "    '''\n",
    "\n",
    "    px = df['Px'].values\n",
    "    py = df['Py'].values\n",
    "    pz = df['Pz'].values\n",
    "\n",
    "    p = np.sqrt(px**2 + py**2 + pz**2)\n",
    "    theta = np.arccos(pz / p) / np.pi * 180\n",
    "    phi = np.arctan2(py, px) / np.pi * 180\n",
    "\n",
    "    df['P'] = p\n",
    "    df['theta'] = theta\n",
    "    df['phi'] = phi\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9abe35-6f8a-494d-a066-4940e8a7d83e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#reading data from .root file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#dfs['DetT1'] = file[f'VirtualDetector/DetT1'].arrays(branches, library='pd')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetT2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVirtualDetector/DetT2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39marrays(branches, library\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDet7\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVirtualDetector/Det7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJGGDet1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVirtualDetector/JGGDet1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39marrays(branches, library\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#removing duplicates\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#dfs['DetT1'] = dfs['DetT1'].drop_duplicates(['EventID', 'TrackID'])\u001b[39;00m\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:826\u001b[0m, in \u001b[0;36mHasBranches.arrays\u001b[0;34m(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library, ak_add_doc, how)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 ranges_or_baskets\u001b[38;5;241m.\u001b[39mappend((branch, basket_num, range_or_basket))\n\u001b[1;32m    825\u001b[0m interp_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mak_add_doc\u001b[39m\u001b[38;5;124m\"\u001b[39m: ak_add_doc}\n\u001b[0;32m--> 826\u001b[0m \u001b[43m_ranges_or_baskets_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranges_or_baskets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbranchid_interpretation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# no longer needed; save memory\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m ranges_or_baskets\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:3023\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets, interp_options)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3017\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(library, uproot\u001b[38;5;241m.\u001b[39minterpretation\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mAwkward)\n\u001b[1;32m   3018\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(interpretation, uproot\u001b[38;5;241m.\u001b[39minterpretation\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mAsObjects)\n\u001b[1;32m   3019\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m cache_key \u001b[38;5;129;01min\u001b[39;00m branchid_to_branch\n\u001b[1;32m   3020\u001b[0m     ):\n\u001b[1;32m   3021\u001b[0m         branchid_to_branch[cache_key]\u001b[38;5;241m.\u001b[39m_awkward_check(interpretation)\n\u001b[0;32m-> 3023\u001b[0m \u001b[43mhasbranches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotifications\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotifications\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplace\u001b[39m(ranges_or_baskets, original_index, basket):\n\u001b[1;32m   3026\u001b[0m     branch, basket_num, range_or_basket \u001b[38;5;241m=\u001b[39m ranges_or_baskets[original_index]\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/source/fsspec.py:169\u001b[0m, in \u001b[0;36mFSSpecSource.chunks\u001b[0;34m(self, ranges, notifications)\u001b[0m\n\u001b[1;32m    160\u001b[0m     coroutine \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs\u001b[38;5;241m.\u001b[39m_cat_ranges(paths\u001b[38;5;241m=\u001b[39mpaths, starts\u001b[38;5;241m=\u001b[39mstarts, ends\u001b[38;5;241m=\u001b[39mends)\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_impl\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39msubmit(coroutine)\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcoalesce_requests\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotifications\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coalesce_config\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/source/coalesce.py:123\u001b[0m, in \u001b[0;36mcoalesce_requests\u001b[0;34m(ranges, submit_fn, source, notifications, config)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m DEFAULT_CONFIG\n\u001b[1;32m    122\u001b[0m all_requests \u001b[38;5;241m=\u001b[39m [RangeRequest(start, stop, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m start, stop \u001b[38;5;129;01min\u001b[39;00m ranges]\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m merged_request \u001b[38;5;129;01min\u001b[39;00m _coalesce(all_requests, config):\n\u001b[1;32m    124\u001b[0m     future \u001b[38;5;241m=\u001b[39m submit_fn(merged_request\u001b[38;5;241m.\u001b[39mranges())\n\u001b[1;32m    125\u001b[0m     merged_request\u001b[38;5;241m.\u001b[39mset_future(future)\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/source/coalesce.py:97\u001b[0m, in \u001b[0;36m_coalesce\u001b[0;34m(ranges, config)\u001b[0m\n\u001b[1;32m     95\u001b[0m request_bytes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     96\u001b[0m first_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m _merge_adjacent(ranges, config):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clusters \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28mlen\u001b[39m(clusters) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmax_request_ranges\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m request_bytes \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(cluster) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmax_request_bytes\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (first_request \u001b[38;5;129;01mand\u001b[39;00m request_bytes \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmin_first_request_bytes)\n\u001b[1;32m    102\u001b[0m     ):\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m CoalescedRequest(clusters)\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/source/coalesce.py:85\u001b[0m, in \u001b[0;36m_merge_adjacent\u001b[0;34m(ranges, config)\u001b[0m\n\u001b[1;32m     83\u001b[0m cluster \u001b[38;5;241m=\u001b[39m Cluster([])\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_range \u001b[38;5;129;01min\u001b[39;00m sorted_ranges:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cluster\u001b[38;5;241m.\u001b[39mranges \u001b[38;5;129;01mand\u001b[39;00m current_range\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m-\u001b[39m \u001b[43mcluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m \u001b[38;5;241m>\u001b[39m config\u001b[38;5;241m.\u001b[39mmax_range_gap:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cluster\n\u001b[1;32m     87\u001b[0m         cluster \u001b[38;5;241m=\u001b[39m Cluster([])\n",
      "File \u001b[0;32m/exp/lariat/app/users/gcicogna/beamline/Analysis/analysis-env/lib/python3.9/site-packages/uproot/source/coalesce.py:57\u001b[0m, in \u001b[0;36mCluster.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstop\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mrange\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranges)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "branches = ['x', 'y', 'z', 'Px', 'Py', 'Pz', 'PDGid', 'EventID', 'TrackID']\n",
    "\n",
    "dfs = {} # dictionary to store dataframes, list accessible by detector name\n",
    "\n",
    "#reading data from .root file\n",
    "\n",
    "#dfs['DetT1'] = file[f'VirtualDetector/DetT1'].arrays(branches, library='pd')\n",
    "dfs['DetT2'] = file[f'VirtualDetector/DetT2'].arrays(branches, library='pd')\n",
    "dfs['Det7'] = file[f'VirtualDetector/Det7'].arrays(branches, library='pd')\n",
    "dfs['JGGDet1'] = file[f'VirtualDetector/JGGDet1'].arrays(branches, library='pd')\n",
    "\n",
    "#removing duplicates\n",
    "#dfs['DetT1'] = dfs['DetT1'].drop_duplicates(['EventID', 'TrackID'])\n",
    "dfs['DetT2'] = dfs['DetT2'].drop_duplicates(['EventID', 'TrackID'])\n",
    "dfs['Det7'] = dfs['Det7'].drop_duplicates(['EventID', 'TrackID'])\n",
    "dfs['JGGDet1'] = dfs['JGGDet1'].drop_duplicates(['EventID', 'TrackID'])\n",
    "\n",
    "#adding total momentum, theta and phi to the dataframes\n",
    "#dfs['DetT1'] = add_vars_to_df(dfs['DetT1'])\n",
    "dfs['DetT2'] = add_vars_to_df(dfs['DetT2'])\n",
    "dfs['Det7'] = add_vars_to_df(dfs['Det7'])\n",
    "dfs['JGGDet1'] = add_vars_to_df(dfs['JGGDet1'])\n",
    "\n",
    "# print(dfs['DetT1'])\n",
    "# print(dfs['JGGDet1'])\n",
    "\n",
    "# df2.loc[(df2['EventID'] == 29970112.0) & (df2['TrackID'] == 121664.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3536ab-471d-4479-b2ec-7832791c4f30",
   "metadata": {},
   "source": [
    "## Merge TTrees\n",
    "\n",
    "Merging TTrees for 3 detectors.\n",
    "\n",
    "Second merge: DetT2 and Det7.\n",
    "Third merge: (first) and JGGDet1.\n",
    "\n",
    "The goal is to keep particles that are present in the 3 detectors [DetT2, Det7, JGGDet1], to select particles to trigger on.\n",
    "\n",
    "The detectors are on-axis with the beam. \n",
    "\n",
    "**Plots directories**:\n",
    "- JGG is ON, LArIAT magnets are OFF (*lariat_off_JGG_on*);\n",
    "- JGG is OFF, LArIAT magnets are OFF;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670485e-5838-4497-9cb3-2a01cf505a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Merge: DetT1 and DetT2 -----------------------------------------------------------------------------------------------------\n",
    "#df_merged1 = dfs['DetT1'].merge(dfs['DetT2'], on=['EventID', 'TrackID'], how='left', indicator=True, suffixes=('_DetT1', '_DetT2'))\n",
    "\n",
    "#Drop particles that are not in both detectors\n",
    "#df_merged1 = df_merged1[df_merged1['_merge'] == 'both']\n",
    "\n",
    "#Drop PDGid columns (redundant)\n",
    "#df_merged1 = df_merged1.drop(['PDGid_DetT1'], axis=1)\n",
    "\n",
    "#Rename PDGid column\n",
    "#df_merged1 = df_merged1.rename(columns={'PDGid_DetT2': 'PDGid'})\n",
    "\n",
    "#Second Merge: DetT1+DetT2 (df_merged1) and Det7 -----------------------------------------------------------------------------------------------------\n",
    "df_merged2 = dfs['DetT2'].merge(dfs['Det7'], on=['EventID', 'TrackID'], how='left', indicator='_merge1', suffixes=('_DetT2', '_Det7'))\n",
    "df_merged2 = df_merged2[df_merged2['_merge1'] == 'both']\n",
    "df_merged2 = df_merged2.drop(['PDGid_Det7'], axis=1)\n",
    "\n",
    "#Third Merge: DetT1+DetT2+Det7 (df_merged2) and JGGDet1 -----------------------------------------------------------------------------------------------------\n",
    "df = df_merged2.merge(dfs['JGGDet1'], on=['EventID', 'TrackID'], how='left', indicator='_merge_final', suffixes=('_merge1', '_JGGDet1'))\n",
    "df = df[df['_merge_final'] == 'both']\n",
    "df = df.drop(['PDGid_JGGDet1'], axis=1, errors='ignore')\n",
    "\n",
    "df = df.rename(columns={'x':'x_JGGDet1',\n",
    "                        'y':'y_JGGDet1',\n",
    "                        'z':'z_JGGDet1',\n",
    "                        'Px':'Px_JGGDet1', \n",
    "                        'Py':'Py_JGGDet1', \n",
    "                        'Pz':'Pz_JGGDet1', \n",
    "                        'P':'P_JGGDet1', \n",
    "                        'theta':'theta_JGGDet1', \n",
    "                        'phi':'phi_JGGDet1'})\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9546ac85-2b75-405a-9c0f-a72313049c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.query('PDGid==11 and P_Det7 < 100 and theta_Det7 < 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bc603-f6f8-434f-b7bb-b53339894787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_labels(df, det='JGGDet1', variable='p', p_cut=80):\n",
    "    '''\n",
    "    Returns values to plot with their labels\n",
    "\n",
    "    Args:\n",
    "        det (str): the detector to plot\n",
    "        variable (str): the variable to plot\n",
    "        p_cut (int): momentum cut\n",
    "    '''\n",
    "\n",
    "    # Apply a momentum cut\n",
    "    df_ = df.query(f'P_{det} > {p_cut}')\n",
    "\n",
    "    # if det == 'Det7':\n",
    "    #     df_ = df_.query(f'theta_{det} < 1')\n",
    "\n",
    "    pdg = df_['PDGid'].values\n",
    "\n",
    "    if variable == 'p':\n",
    "        var = df_[f'P_{det}'].values\n",
    "    elif variable == 'theta':\n",
    "        var = df_[f'theta_{det}'].values\n",
    "    elif variable == 'phi':\n",
    "        var = df_[f'phi_{det}'].values\n",
    "        \n",
    "    kaons = var[np.abs(pdg)==321]\n",
    "    positrons = var[pdg==-11]\n",
    "    electrons = var[pdg==+11]\n",
    "    muons = var[np.abs(pdg)==13]\n",
    "    protons = var[np.abs(pdg)==2212]\n",
    "    pions = var[np.abs(pdg)==211]\n",
    "    others = var[ (np.abs(pdg)!=321) & (np.abs(pdg)!=11) & (np.abs(pdg)!=13) & (np.abs(pdg)!=2212) & (np.abs(pdg)!=211)]\n",
    "    gamma = var[np.abs(pdg)==22]\n",
    "    \n",
    "    values = [\n",
    "        others,\n",
    "        gamma,\n",
    "        kaons,\n",
    "        positrons,\n",
    "        electrons,\n",
    "        muons,\n",
    "        protons,\n",
    "        pions,\n",
    "    ]\n",
    "\n",
    "    tot = len(kaons) + len(electrons) + len(positrons) + len(muons) + len(protons) + len(pions)\n",
    "    tot += len(others)\n",
    "    tot += len(gamma)\n",
    "    \n",
    "    labels = [\n",
    "        'others' + f', ({len(others) / tot * 100:.1f}%)',\n",
    "        'gamma' + f', ({len(gamma) / tot * 100:.1f}%)',\n",
    "        r'$K^\\pm$' + f', ({len(kaons):.2e}, {len(kaons) / tot * 100:.1f}%)',\n",
    "        r'$e^+$' + f', ({len(positrons):.2e}, {len(positrons) / tot * 100:.1f}%)',\n",
    "        r'$e^-$' + f', ({len(electrons):.2e}, {len(electrons) / tot * 100:.1f}%)',\n",
    "        r'$\\mu^\\pm$' + f', ({len(muons):.2e}, {len(muons) / tot * 100:.1f}%)',\n",
    "        r'$p^\\pm$' + f', ({len(protons):.2e}, {len(protons) / tot * 100:.1f}%)',\n",
    "        r'$\\pi^\\pm$' + f', ({len(pions):.2e}, {len(pions) / tot * 100:.1f}%)'\n",
    "    ]\n",
    "\n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761af13f-a3aa-43a0-8373-2bd4b6c8f38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for det in det_list:\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18, 5))\n",
    "\n",
    "    x_axis = {'p': 'Momentum [GeV]',\n",
    "              'theta': 'Theta [deg]',\n",
    "              'phi': 'Phi [deg]'}\n",
    "    x_bins = {'p': np.linspace(0, 2500, 50),\n",
    "              'theta': np.linspace(0, 180, 50),\n",
    "              'phi': np.linspace(-180, 180, 50)}\n",
    "\n",
    "    for i, variable in enumerate(['p', 'theta', 'phi']):\n",
    "\n",
    "        p_cut = 80\n",
    "\n",
    "        values, labels = get_values_labels(df, det, variable, p_cut)\n",
    "    \n",
    "        bins = x_bins[variable]\n",
    "        \n",
    "        ax[i].hist(values, bins=bins, color=colors, label=labels, stacked=True)\n",
    "        \n",
    "        ax[i].legend()\n",
    "        handles, labels = ax[i].get_legend_handles_labels()\n",
    "        ax[i].legend(handles[::-1], labels[::-1], title='64 GeV, +60 Amps',)\n",
    "    \n",
    "        ax[i].set_xlabel(x_axis[variable])\n",
    "        ax[i].set_ylabel(f'Particles / {n_pions:.1e} ' + r'$\\pi$' + f' on target ({n_hours} hours of data)' )\n",
    "        ax[i].set_title(f'Detector: {det}; Config: {config}', loc='right', fontsize=8)\n",
    "        ax[i].set_title(f'$p>{p_cut}$ MeV', loc='left', fontsize=8)\n",
    "        \n",
    "        # if det == 'Det7' or det == 'Det8' or 'JGG' in det:\n",
    "        #     ax[i].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(_save_dir + f'allspectra_g4blsimpleT_df_{config}_det{det}.jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9df62-d97b-4999-afd8-f43fbf5aafb5",
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_2d_histogram(ax, x_data, y_data, title, vmin=None, vmax=None):\n",
    "    x_min, x_max = x_data.min(), x_data.max()\n",
    "    y_min, y_max = y_data.min(), y_data.max()\n",
    "\n",
    "    # Set bin edges dynamically with a buffer\n",
    "    xedges = np.linspace(x_min - 60, x_max + 60, 50)\n",
    "    yedges = np.linspace(y_min - 60, y_max + 60, 50)\n",
    "\n",
    "    # Calculate 2D histogram\n",
    "    hist, xedges, yedges = np.histogram2d(x_data, y_data, bins=[xedges, yedges])\n",
    "\n",
    "    # Plot the histogram with colormap\n",
    "    c = ax.pcolormesh(xedges, yedges, hist.T, cmap='viridis', norm=Normalize(vmin=vmin, vmax=vmax))\n",
    "    ax.set_xlabel('X [mm]')\n",
    "    ax.set_ylabel('Y [mm]')\n",
    "    ax.set_title(title, loc='right', fontsize=8)\n",
    "\n",
    "    # Add colorbar\n",
    "    fig.colorbar(c, ax=ax, label='Occurrences')\n",
    "\n",
    "def calculate_global_limits(df, det, pz_threshold=None):\n",
    "    # Filter data\n",
    "    x_data = df[f'x_{det}'].values\n",
    "    y_data = df[f'y_{det}'].values\n",
    "\n",
    "    if pz_threshold is not None:\n",
    "        df_filtered = df.query(f'Pz_JGGDet1 > {pz_threshold}')\n",
    "        x_data = df_filtered[f'x_{det}'].values\n",
    "        y_data = df_filtered[f'y_{det}'].values\n",
    "\n",
    "    # Calculate global min and max\n",
    "    x_min, x_max = x_data.min(), x_data.max()\n",
    "    y_min, y_max = y_data.min(), y_data.max()\n",
    "\n",
    "    return x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022f2ba-3096-466c-8865-9e64dfee2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in det_list:\n",
    "\n",
    "    df_e = df[abs(df['PDGid']) == 11]\n",
    "    \n",
    "    # Calculate global limits for x and y axes\n",
    "    x_min_full, x_max_full, y_min_full, y_max_full = calculate_global_limits(df, det)\n",
    "    x_min_e, x_max_e, y_min_e, y_max_e = calculate_global_limits(df_e, det)\n",
    "    x_min_p, x_max_p, y_min_p, y_max_p = calculate_global_limits(df, det, pz_threshold=100)\n",
    "\n",
    "    # Combine limits to ensure consistency across all plots\n",
    "    x_min_combined = min(x_min_full, x_min_e, x_min_p)\n",
    "    x_max_combined = max(x_max_full, x_max_e, x_max_p)\n",
    "    y_min_combined = min(y_min_full, y_min_e, y_min_p)\n",
    "    y_max_combined = max(y_max_full, y_max_e, y_max_p)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(20, 5))\n",
    "\n",
    "    # Full Data\n",
    "    plot_2d_histogram(ax[0], df[f'x_{det}'].values, df[f'y_{det}'].values,\n",
    "                      f'Detector: {det}', vmin=0, vmax=None)\n",
    "    ax[0].set_xlim(x_min_combined, x_max_combined)\n",
    "    ax[0].set_ylim(y_min_combined, y_max_combined)\n",
    "\n",
    "    # Electrons + Positrons\n",
    "    x_data_e = df.query('abs(PDGid) == 11')[f'x_{det}'].values\n",
    "    y_data_e = df.query('abs(PDGid) == 11')[f'y_{det}'].values\n",
    "    plot_2d_histogram(ax[1], x_data_e, y_data_e, f'Detector: {det} - Electrons + Positrons',\n",
    "                      vmin=0, vmax=None)\n",
    "    ax[1].set_xlim(x_min_combined, x_max_combined)\n",
    "    ax[1].set_ylim(y_min_combined, y_max_combined)\n",
    "\n",
    "    # Electrons Only, p > 100 MeV\n",
    "    x_data_p = df.query('abs(PDGid) == 11 and Pz_JGGDet1 > 100')[f'x_{det}'].values\n",
    "    y_data_p = df.query('abs(PDGid) == 11 and Pz_JGGDet1 > 100')[f'y_{det}'].values\n",
    "    plot_2d_histogram(ax[2], x_data_p, y_data_p, f'Detector: {det} - Electrons + Positrons, p > 100 MeV',\n",
    "                      vmin=0, vmax=None)\n",
    "    ax[2].set_xlim(x_min_combined, x_max_combined)\n",
    "    ax[2].set_ylim(y_min_combined, y_max_combined)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(_save_dir + f'posspectra_g4blsimpleT_df_{config}_det{det}.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b16f9-c9bf-470e-a4b3-7925af976523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in det_list:\n",
    "\n",
    "    values, labels = get_values_labels(df, det, 'p', p_cut)\n",
    "\n",
    "    # Creating a single figure for PID\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "    # Occurrences for each PID\n",
    "    counts = [len(v) for v in values]\n",
    "    total_count = sum(counts)\n",
    "    \n",
    "    if total_count == 0:\n",
    "        # Handle division by zero case\n",
    "        percentages = [0] * len(counts)\n",
    "    else:\n",
    "        percentages = [(count / total_count) * 100 for count in counts]\n",
    "\n",
    "    # Create bar plot with particle counts and their types\n",
    "    ax.barh(labels, percentages, color=colors)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(f'Particles / {n_pions:.1e}' + r'$\\pi$' + f'on target ({n_hours} hours of data)')\n",
    "    ax.set_ylabel('Particle Type')\n",
    "    ax.set_title(f'PID Occurrences in {det} with $p > {p_cut}$ MeV [Config: {config}]', loc='right', fontsize=8)\n",
    "\n",
    "    # Optionally add value labels on the bars\n",
    "    for i, v in enumerate(percentages):\n",
    "        ax.text(v + 1, i, f'{v:.2f}%', color='black', va='center')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(_save_dir + f'pid_g4blsimpleT_df_{config}_det{det}.jpg')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f205f5a-e3c3-4f10-88c9-655de7ad577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_focus = 'Gamma'\n",
    "\n",
    "# Define the mapping from particle focus to IDs\n",
    "particle_id_mapping = {\n",
    "    'Electrons': [11],\n",
    "    'Positrons': [-11],\n",
    "    'Gamma': [22],\n",
    "    'Both (e)': [11, -11],        # Both Electrons and Positrons\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5d469-8a0e-4ae3-9bca-9886b4edce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Particle focused on is {particle_focus}\")\n",
    "\n",
    "colors_ = colors[:6]\n",
    "colors_=colors_[::-1]\n",
    "#print(len(colors_))\n",
    "\n",
    "for det in det_list:\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18, 5))\n",
    "\n",
    "    # Define momentum ranges and labels\n",
    "    #momentum_ranges = [(500, np.inf), (400, 500), (300, 400), (200, 300), (100, 200), (0,100)]\n",
    "    #momentum_labels = ['>500 MeV','400-500 MeV','300-400 Mev','200-300 MeV','100-200 MeV','0-100 MeV']\n",
    "    momentum_ranges = [(0, 100), (100, 200), (200, 300), (300, 400), (400, 500), (500, np.inf)]\n",
    "    momentum_labels = ['<100 MeV', '100-200 MeV', '200-300 MeV', '300-400 MeV', '400-500 MeV', '>500 MeV']\n",
    "\n",
    "    #colors_ = plt.cm.Set1(np.linspace(0, 1, len(momentum_ranges)))\n",
    "    \n",
    "    # Define axes for the histograms\n",
    "    x_axis = {'p': 'Momentum [GeV]', 'theta': 'Theta [deg]', 'phi': 'Phi [deg]'}\n",
    "    x_bins = {'p': np.linspace(0, 2500, 50), 'theta': np.linspace(0, 180, 50), 'phi': np.linspace(-180, 180, 50)}\n",
    "    \n",
    "    # Filter data for ABS pdgid = 11; electrons AND positrons\n",
    "    #df_focus = df[abs(df['PDGid']) == 11]\n",
    "\n",
    "     # Ensure particle_focus is a valid key\n",
    "    if particle_focus not in particle_id_mapping:\n",
    "        raise ValueError(f\"Invalid particle_focus: {particle_focus}\")\n",
    "\n",
    "    # Get the list of IDs for the specified particle_focus\n",
    "    ids_to_filter = particle_id_mapping[particle_focus]\n",
    "\n",
    "    #print(ids_to_filter)\n",
    "    \n",
    "    # Filter DataFrame based on IDs\n",
    "    df_focus = df[df['PDGid'].isin(ids_to_filter)]\n",
    "    \n",
    "    # Get values and labels for the selected detector and variable\n",
    "    values, labels = get_values_labels(df_focus, det, 'p', p_cut = 0)\n",
    "    phi_values, _ = get_values_labels(df_focus, det, 'phi', p_cut = 0)\n",
    "    theta_values, _ = get_values_labels(df_focus, det, 'theta', p_cut = 0)\n",
    "\n",
    "    # Flatten the array of arrays, ignoring empty arrays\n",
    "    flattened_values = np.concatenate([v for v in values if v.size > 0], axis=None)\n",
    "    flattened_values = np.array(flattened_values, dtype=float)\n",
    "\n",
    "    # Flatten theta values similarly\n",
    "    flattened_theta_values = np.concatenate([v for v in theta_values if v.size > 0], axis=None)\n",
    "    flattened_theta_values = np.array(flattened_theta_values, dtype=float)\n",
    "\n",
    "    # Flatten phi values similarly\n",
    "    flattened_phi_values = np.concatenate([v for v in phi_values if v.size > 0], axis=None)\n",
    "    flattened_phi_values = np.array(flattened_phi_values, dtype=float)\n",
    "\n",
    "    #Empty array to contain all values (arrays) of each momentum range\n",
    "    filtered_=[]\n",
    "    filtered_theta=[]\n",
    "    filtered_phi=[]\n",
    "\n",
    "    labels=[]\n",
    "    \n",
    "    # Create stacked histograms for momentum ranges in the first subplot\n",
    "    for i, ((low, high), label) in enumerate(zip(momentum_ranges, momentum_labels)):\n",
    "        # Filter values based on the current momentum range\n",
    "        mask = (flattened_values >= low) & (flattened_values < high)\n",
    "\n",
    "        filtered_values = flattened_values[mask]\n",
    "        filtered_theta_values = flattened_theta_values[mask]\n",
    "        filtered_phi_values = flattened_phi_values[mask]\n",
    "\n",
    "        filtered_.append(filtered_values)\n",
    "        filtered_theta.append(filtered_theta_values)\n",
    "        filtered_phi.append(filtered_phi_values)\n",
    "\n",
    "        labels.append(label)\n",
    "        \n",
    "        \n",
    "    # Plot histograms for each momentum range\n",
    "    ax[0].hist(filtered_, bins=x_bins['p'], label=labels, color=colors_, histtype='stepfilled', stacked=True)\n",
    "\n",
    "    # Filter theta values for the same momentum range\n",
    "    ax[1].hist(filtered_theta, bins=x_bins['theta'], label=labels, color=colors_, histtype='stepfilled', stacked=True)\n",
    "\n",
    "    # Filter phi values for the same momentum range\n",
    "    ax[2].hist(filtered_phi, bins=x_bins['phi'], label=labels, color=colors_, histtype='stepfilled', stacked=True)\n",
    "    \n",
    "    \n",
    "    ax[0].set_xlabel(x_axis['p'])\n",
    "    ax[0].set_ylabel(f'Particles / {n_pions:.1e} ' + r'$\\pi$' + f' on target ({n_hours} hours of data)')\n",
    "    ax[0].set_title(f'Detector: {det}; Config: {config}', loc='right', fontsize=8)\n",
    "    ax[0].set_title(f'p spectrum for {particle_focus} only', loc='left', fontsize=8)\n",
    "    ax[0].legend(title='Momentum Range', loc='upper right', framealpha=0.1)\n",
    "    \n",
    "    ax[1].set_xlabel(x_axis['theta'])\n",
    "    ax[1].set_ylabel(f'Particles / {n_pions:.1e} ' + r'$\\pi$' + f' on target ({n_hours} hours of data)')\n",
    "    ax[1].set_title(f'Detector: {det}; Config: {config}', loc='right', fontsize=8)\n",
    "    ax[1].set_title(f'Theta distribution for {particle_focus} only', loc='left', fontsize=8)\n",
    "    ax[1].legend(title='Momentum Range', loc='upper right', framealpha=0.1)\n",
    "    \n",
    "    ax[2].set_xlabel(x_axis['phi'])\n",
    "    ax[2].set_ylabel(f'Particles / {n_pions:.1e} ' + r'$\\pi$' + f' on target ({n_hours} hours of data)')\n",
    "    ax[2].set_title(f'Detector: {det}; Config: {config}', loc='right', fontsize=8)\n",
    "    ax[2].set_title(f'Phi distribution for {particle_focus} only', loc='left', fontsize=8)\n",
    "    ax[2].legend(title='Momentum Range', loc='upper right', framealpha=0.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(_save_dir + f'{particle_focus}_spectra_g4blsimpleT_df_{config}_det{det}.jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e216ff1-b5c3-4cb2-834d-7072c44b1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#circular symmetry analysis \n",
    "\n",
    "print(f\"Particle focused on is {particle_focus}\")\n",
    "\n",
    "for det in det_list: \n",
    "    \n",
    "    detector_center = (0, 0)  # (x0, y0)\n",
    "    \n",
    "    # Define maximum radius based on the area of the detector (DetPrime 400 * 470)\n",
    "    max_radius = np.sqrt(470 * 400 / np.pi)  # cm\n",
    "\n",
    "        # Define step size for increasing radius (e.g., 10 cm increments)\n",
    "    radius_steps = np.arange(50, max_radius, 30)\n",
    "    radius_steps=radius_steps[::-1]\n",
    "    \n",
    "     # Ensure particle_focus is a valid key\n",
    "    if particle_focus not in particle_id_mapping:\n",
    "        raise ValueError(f\"Invalid particle_focus: {particle_focus}\")\n",
    "\n",
    "    # Get the list of IDs for the specified particle_focus\n",
    "    ids_to_filter = particle_id_mapping[particle_focus]\n",
    "\n",
    "    #print(ids_to_filter)\n",
    "    \n",
    "    # Filter DataFrame based on IDs\n",
    "    df_focus = df[df['PDGid'].isin(ids_to_filter)]\n",
    "    \n",
    "    # Get values for position (assuming you have 'x' and 'y' coordinates of particles)\n",
    "    x_values = df_focus[f'x_{det}'].values  # x-coordinate of particles\n",
    "    y_values = df_focus[f'y_{det}'].values  # y-coordinate of particles\n",
    "\n",
    "     # Get values for position and other parameters\n",
    "    x_values = df_focus[f'x_{det}'].values\n",
    "    y_values = df_focus[f'y_{det}'].values\n",
    "    p_values = df_focus[f'P_{det}'].values\n",
    "    theta_values = df_focus[f'theta_{det}'].values\n",
    "    phi_values = df_focus[f'phi_{det}'].values\n",
    "    \n",
    "    # Calculate the distance of each particle from the detector's center\n",
    "    distances = np.sqrt((x_values - detector_center[0])**2 + (y_values - detector_center[1])**2)\n",
    "    \n",
    "    # Create the figure and subplots\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18, 5))\n",
    "    colors__ = colors \n",
    "    \n",
    "    # Define axes for the histograms\n",
    "    x_axis = {'p': 'Momentum [GeV]', 'theta': 'Theta [deg]', 'phi': 'Phi [deg]'}\n",
    "    x_bins = {'p': np.linspace(0, 2500, 50), 'theta': np.linspace(0, 180, 50), 'phi': np.linspace(-180, 180, 50)}\n",
    "    \n",
    "    # Loop through increasing radii and count particles inside each circle\n",
    "    for i, radius in enumerate(radius_steps):\n",
    "        # Filter particles within the current radius\n",
    "        mask = distances <= radius\n",
    "        filtered_values = p_values[mask]\n",
    "        filtered_theta_values = theta_values[mask]\n",
    "        filtered_phi_values = phi_values[mask]\n",
    "        \n",
    "        # Plot histograms for each variable (p, theta, phi)\n",
    "        ax[0].hist(filtered_values, bins=x_bins['p'], label=f'r < {radius:.1f} cm', color=colors__[i], histtype='stepfilled', stacked=True)\n",
    "        ax[1].hist(filtered_theta_values, bins=x_bins['theta'], label=f'r < {radius:.1f} cm', color=colors__[i], histtype='stepfilled', stacked=True)\n",
    "        ax[2].hist(filtered_phi_values, bins=x_bins['phi'], label=f'r < {radius:.1f} cm', color=colors__[i], histtype='stepfilled', stacked=True)\n",
    "    \n",
    "    # Set axis labels, titles, and legends\n",
    "    for j, var in enumerate(['p', 'theta', 'phi']):\n",
    "        ax[j].set_xlabel(x_axis[var])\n",
    "        ax[j].set_ylabel(f'Particles / {n_pions:.1e} ' + r'$\\pi$' + f' on target ({n_hours} hours of data)')\n",
    "        ax[j].legend(title='Radius [cm]', loc='upper right', framealpha=0.1)\n",
    "\n",
    "    ax[0].set_title(f'Momentum distribution for {particle_focus} within growing circular region', loc='left', fontsize=8)\n",
    "    ax[1].set_title(f'Theta distribution for {particle_focus} within growing circular region', loc='left', fontsize=8)\n",
    "    ax[2].set_title(f'Phi distribution for {particle_focus} within growing circular region', loc='left', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(_save_dir + f'circular_{particle_focus}_spectra_g4blsimpleT_df_{config}_det{det}.jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a792b66-bda4-4d7c-a9aa-fb8d29bfb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for det in det_list:\n",
    "    \n",
    "    # Filter data for pdgid = 11 (electrons only)\n",
    "    df_e = df[abs(df['PDGid']) == 11]\n",
    "\n",
    "    x_values_f = df[f'x_{det}'].values  # x-coordinate of particles\n",
    "    y_values_f = df[f'y_{det}'].values  # y-coordinate of particles\n",
    "\n",
    "    x_values_e = df_e[f'x_{det}'].values  # x-coordinate of e\n",
    "    y_values_e = df_e[f'y_{det}'].values  # y-coordinate of e\n",
    "\n",
    "    # Calculate the distance of each particle from the detector's center\n",
    "    distances_f = np.sqrt((x_values_f - detector_center[0])**2 + (y_values_f - detector_center[1])**2)\n",
    "    distances_e = np.sqrt((x_values_e - detector_center[0])**2 + (y_values_e - detector_center[1])**2)\n",
    "\n",
    "    for i, radius in enumerate(radius_steps):\n",
    "        fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(12, 5))\n",
    "        \n",
    "        print(f'Radius: {radius} at step {i}')\n",
    "        # Filter particles within the current radius\n",
    "        mask_full = distances_f <= radius\n",
    "        mask_e = distances_e <= radius\n",
    "\n",
    "        #Full Data\n",
    "        x_full =  x_values_f[mask_full]\n",
    "        y_full = y_values_f[mask_full]\n",
    "\n",
    "        plot_2d_histogram(ax[0], x_full, y_full, f'Detector: {det}; Radius <= {radius}')\n",
    "\n",
    "        #Electrons + Positrons\n",
    "        x_data_e = x_values_e[mask_e]\n",
    "        y_data_e = y_values_e[mask_e]\n",
    "\n",
    "        plot_2d_histogram(ax[1], x_data_e, y_data_e, f'Detector: {det} - Electrons Only; Radius <= {radius}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(_save_dir + f'spectra_g4blsimpleT_df_pos_{config}_det{det}.jpg')\n",
    "        plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
